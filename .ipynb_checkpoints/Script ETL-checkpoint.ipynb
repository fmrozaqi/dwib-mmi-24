{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014d5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70550d",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bede32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETLPipeline:\n",
    "    \"\"\"Class untuk mengotomatisasi proses ETL\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path='brazil_stock_market.db'):\n",
    "        \"\"\"Inisialisasi pipeline\"\"\"\n",
    "        self.conn = duckdb.connect(db_path)\n",
    "        self.initialized = False\n",
    "        self.log_table_setup()\n",
    "    \n",
    "    def log_table_setup(self):\n",
    "        \"\"\"Membuat tabel log untuk melacak proses ETL\"\"\"\n",
    "        self.conn.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS \"etlLog\" (\n",
    "            \"logId\" INTEGER PRIMARY KEY,\n",
    "            \"processName\" VARCHAR,\n",
    "            \"startTime\" TIMESTAMP,\n",
    "            \"endTime\" TIMESTAMP,\n",
    "            \"recordsProcessed\" INTEGER,\n",
    "            \"status\" VARCHAR,\n",
    "            \"message\" VARCHAR\n",
    "        )\n",
    "        \"\"\")\n",
    "    \n",
    "    def log_process_start(self, process_name):\n",
    "        \"\"\"Mencatat mulainya proses ETL\"\"\"\n",
    "        log_id = self.conn.execute('SELECT COALESCE(MAX(logId), 0) + 1 FROM \"etlLog\"').fetchone()[0]\n",
    "        self.conn.execute(\"\"\"\n",
    "        INSERT INTO \"etlLog\" (logId, processName, startTime, status)\n",
    "        VALUES (?, ?, CURRENT_TIMESTAMP, 'RUNNING')\n",
    "        \"\"\", [log_id, process_name])\n",
    "        return log_id\n",
    "    \n",
    "    def log_process_end(self, log_id, records=0, status='SUCCESS', message=None):\n",
    "        \"\"\"Mencatat selesainya proses ETL\"\"\"\n",
    "        self.conn.execute(\"\"\"\n",
    "        UPDATE \"etlLog\"\n",
    "        SET endTime = CURRENT_TIMESTAMP,\n",
    "            recordsProcessed = ?,\n",
    "            status = ?,\n",
    "            message = ?\n",
    "        WHERE logId = ?\n",
    "        \"\"\", [records, status, message, log_id])\n",
    "\n",
    "    def ensure_common_columns(self):\n",
    "        \"\"\"\n",
    "        Ensure all target tables have 'effectiveDate', 'expirationDate', and 'currentFlag' columns.\n",
    "        \"\"\"\n",
    "        columns_to_add = [\n",
    "            (\"effectiveDate\", \"DATE\"),\n",
    "            (\"expirationDate\", \"DATE\"),\n",
    "            (\"currentFlag\", \"BOOLEAN\")\n",
    "        ]\n",
    "\n",
    "        target_tables = [\"dimCoin\", \"dimCompany\"]\n",
    "\n",
    "        for table in target_tables:\n",
    "            for column_name, column_type in columns_to_add:\n",
    "                alter_sql = f\"\"\"\n",
    "                ALTER TABLE {table}\n",
    "                ADD COLUMN IF NOT EXISTS {column_name} {column_type}\n",
    "                \"\"\"\n",
    "                self.conn.execute(alter_sql)\n",
    "                \n",
    "    def initialize_warehouse(self):\n",
    "        \"\"\"Inisialisasi skema data warehouse jika belum ada\"\"\"\n",
    "        if self.initialized:\n",
    "            return\n",
    "        \n",
    "        log_id = self.log_process_start(\"initialize_warehouse\")\n",
    "        \n",
    "        try:\n",
    "            # Dimensi Company\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS \"dimCompany\" (\n",
    "                \"keyCompany\" INT NOT NULL,\n",
    "                \"stockCodeCompany\" VARCHAR(32) NOT NULL,\n",
    "                \"nameCompany\" VARCHAR(64) NOT NULL,\n",
    "                \"sectorCodeCompany\" VARCHAR(32) NOT NULL,\n",
    "                \"sectorCompany\" VARCHAR(256) NOT NULL,\n",
    "                \"segmentCompany\" VARCHAR(256) NOT NULL,\n",
    "                \"startedAt\" TIMESTAMP NOT NULL DEFAULT NOW(),\n",
    "                \"endedAt\" TIMESTAMP NULL,\n",
    "                \"isActive\" BOOLEAN NOT NULL DEFAULT TRUE,\n",
    "                CONSTRAINT companyPK PRIMARY KEY (\"keyCompany\")\n",
    "            );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Dimensi Coin\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS \"dimCoin\" (\n",
    "                \"keyCoin\" INT NOT NULL,\n",
    "                \"abbrevCoin\" VARCHAR(32) NOT NULL,\n",
    "                \"nameCoin\" VARCHAR(32) NOT NULL,\n",
    "                \"symbolCoin\" VARCHAR(8) NOT NULL,\n",
    "                \n",
    "                CONSTRAINT coinPK PRIMARY KEY (keyCoin)\n",
    "            );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Dimensi Time\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS \"dimTime\" (\n",
    "                \"keyTime\" INT NOT NULL,\n",
    "                \"datetime\" VARCHAR(32) NOT NULL,\n",
    "                \"dayTime\" SMALLINT NOT NULL,\n",
    "                \"dayWeekTime\" SMALLINT NOT NULL,\n",
    "                \"dayWeekAbbrevTime\" VARCHAR(32) NOT NULL,\n",
    "                \"dayWeekCompleteTime\" VARCHAR(32) NOT NULL,\n",
    "                \"monthTime\" SMALLINT NOT NULL,\n",
    "                \"monthAbbrevTime\" VARCHAR(32) NOT NULL,\n",
    "                \"monthCompleteTime\" VARCHAR(32) NOT NULL,\n",
    "                \"bimonthTime\" SMALLINT NOT NULL,\n",
    "                \"quarterTime\" SMALLINT NOT NULL,\n",
    "                \"semesterTime\" SMALLINT NOT NULL,\n",
    "                \"yearTime\" INT NOT NULL,\n",
    "                \n",
    "                CONSTRAINT timePK PRIMARY KEY (\"keyTime\")\n",
    "            );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Tabel fakta Coins\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS \"factCoins\" (\n",
    "                \"keyTime\" INT NOT NULL,\n",
    "                \"keyCoin\" INT NOT NULL,\n",
    "                \"valueCoin\" FLOAT NOT NULL,\n",
    "                \n",
    "                FOREIGN KEY (keyTime) REFERENCES dimTime(keyTime),\n",
    "                FOREIGN KEY (keyCoin) REFERENCES dimCoin(keyCoin),\n",
    "                CONSTRAINT coinsPK PRIMARY KEY(keyTime, keyCoin)\n",
    "            );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Tabel fakta Stocks\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS \"factStocks\" (\n",
    "                \"keyTime\" INT NOT NULL,\n",
    "                \"keyCompany\" INT NOT NULL,\n",
    "                \"openValueStock\" FLOAT NOT NULL,\n",
    "                \"closeValueStock\" FLOAT NOT NULL,\n",
    "                \"highValueStock\" FLOAT NOT NULL,\n",
    "                \"lowValueStock\" FLOAT NOT NULL,\n",
    "                \"quantityStock\" FLOAT NOT NULL,\n",
    "                \n",
    "                FOREIGN KEY (keyTime) REFERENCES dimTime(keyTime),\n",
    "                FOREIGN KEY (keyCompany) REFERENCES dimCompany(keyCompany),\n",
    "                CONSTRAINT stocksPK PRIMARY KEY(keyTime, keyCompany)\n",
    "            );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Menambahkan column SCD\n",
    "            self.ensure_common_columns()\n",
    "            \n",
    "            # Berhasil inisialisasi\n",
    "            self.initialized = True\n",
    "            self.log_process_end(log_id, status='SUCCESS', message='Data warehouse schema initialized')\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
    "            raise\n",
    "    \n",
    "    def extract_all_sources(self):\n",
    "        \"\"\"Ekstrak data dari semua sumber\"\"\"\n",
    "        log_id = self.log_process_start(\"extract_all_sources\")\n",
    "        \n",
    "        try:\n",
    "            # Bersihkan tabel staging\n",
    "            self.conn.execute(\"DROP TABLE IF EXISTS stagingCoin\")\n",
    "            self.conn.execute(\"DROP TABLE IF EXISTS stagingCompany\")\n",
    "            self.conn.execute(\"DROP TABLE IF EXISTS stagingTime\")\n",
    "            self.conn.execute(\"DROP TABLE IF EXISTS stagingCoinValue\")\n",
    "            self.conn.execute(\"DROP TABLE IF EXISTS stagingStockValue\")\n",
    "            \n",
    "            # Ekstrak data dari file CSV\n",
    "            # Create staging tables from CSVs\n",
    "            self.conn.execute(\"CREATE TABLE stagingCoin AS SELECT * FROM read_csv_auto('data/dimCoin.csv')\")\n",
    "            self.conn.execute(\"CREATE TABLE stagingCompany AS SELECT * FROM read_csv_auto('data/dimCompany.csv')\")\n",
    "            self.conn.execute(\"CREATE TABLE stagingTime AS SELECT * FROM read_csv_auto('data/dimTime.csv')\")\n",
    "            self.conn.execute(\"CREATE TABLE stagingCoinValue AS SELECT * FROM read_csv_auto('data/factCoins.csv')\")\n",
    "            self.conn.execute(\"CREATE TABLE stagingStockValue AS SELECT * FROM read_csv_auto('data/factStocks.csv')\")\n",
    "            \n",
    "            # Hitung total jumlah catatan\n",
    "            total_records = 0\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingCoin\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingCompany\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingTime\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingCoinValue\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingStockValue\").fetchone()[0]\n",
    "            \n",
    "            self.log_process_end(log_id, records=total_records, status='SUCCESS')\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
    "            raise\n",
    "    \n",
    "    def transform_data(self):\n",
    "        \"\"\"Transformasi data dari tabel staging\"\"\"\n",
    "        log_id = self.log_process_start(\"transform_data\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Transformasi dimensi Coin\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE OR REPLACE TABLE stagingDimCoin AS\n",
    "            SELECT\n",
    "                keyCoin,\n",
    "                abbrevCoin,\n",
    "                nameCoin,\n",
    "                symbolCoin,\n",
    "                '2022-01-01'::DATE AS effectiveDate,\n",
    "                NULL::DATE AS expirationDate,\n",
    "                TRUE AS currentFlag\n",
    "            FROM stagingCoin\n",
    "            \"\"\")\n",
    "\n",
    "            # 2. Transformasi dimensi Company\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE OR REPLACE TABLE stagingDimCompany AS\n",
    "            SELECT\n",
    "                keyCompany,\n",
    "                stockCodeCompany,\n",
    "                nameCompany,\n",
    "                sectorCodeCompany,\n",
    "                sectorCompany,\n",
    "                segmentCompany,\n",
    "                NOW() startedAt,\n",
    "                NULL endedAt,\n",
    "                TRUE isActive,\n",
    "                '2022-01-01'::DATE effectiveDate,\n",
    "                NULL::DATE expirationDate,\n",
    "                TRUE currentFlag\n",
    "            FROM stagingCompany\n",
    "            \"\"\")\n",
    "\n",
    "            # 3. Transformasi dimensi Time dengan translasi nama hari & bulan ke Bahasa Inggris\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE OR REPLACE TABLE stagingDimTime AS\n",
    "            SELECT\n",
    "                keyTime,\n",
    "                datetime,\n",
    "                dayTime,\n",
    "                dayWeekTime,\n",
    "\n",
    "                CASE dayWeekAbbrevTime\n",
    "                    WHEN 'SEG' THEN 'MON'\n",
    "                    WHEN 'TER' THEN 'TUE'\n",
    "                    WHEN 'QUA' THEN 'WED'\n",
    "                    WHEN 'QUI' THEN 'THU'\n",
    "                    WHEN 'SEX' THEN 'FRI'\n",
    "                    WHEN 'SAB' THEN 'SAT'\n",
    "                    WHEN 'DOM' THEN 'SUN'\n",
    "                    ELSE dayWeekAbbrevTime\n",
    "                END dayWeekAbbrevTime,\n",
    "\n",
    "                CASE dayWeekCompleteTime\n",
    "                    WHEN 'SEGUNDA' THEN 'MONDAY'\n",
    "                    WHEN 'TERCA' THEN 'TUESDAY'\n",
    "                    WHEN 'QUARTA' THEN 'WEDNESDAY'\n",
    "                    WHEN 'QUINTA' THEN 'THURSDAY'\n",
    "                    WHEN 'SEXTA' THEN 'FRIDAY'\n",
    "                    WHEN 'SABADO' THEN 'SATURDAY'\n",
    "                    WHEN 'DOMINGO' THEN 'SUNDAY'\n",
    "                    ELSE dayWeekCompleteTime\n",
    "                END dayWeekCompleteTime,\n",
    "                \n",
    "                monthTime,\n",
    "\n",
    "                CASE monthAbbrevTime\n",
    "                    WHEN 'JAN' THEN 'JAN'\n",
    "                    WHEN 'FEV' THEN 'FEB'\n",
    "                    WHEN 'MAR' THEN 'MAR'\n",
    "                    WHEN 'ABR' THEN 'APR'\n",
    "                    WHEN 'MAI' THEN 'MAY'\n",
    "                    WHEN 'JUN' THEN 'JUN'\n",
    "                    WHEN 'JUL' THEN 'JUL'\n",
    "                    WHEN 'AGO' THEN 'AUG'\n",
    "                    WHEN 'SET' THEN 'SEP'\n",
    "                    WHEN 'OUT' THEN 'OCT'\n",
    "                    WHEN 'NOV' THEN 'NOV'\n",
    "                    WHEN 'DEZ' THEN 'DEC'\n",
    "                    ELSE monthAbbrevTime\n",
    "                END monthAbbrevTime,\n",
    "                \n",
    "                CASE monthCompleteTime\n",
    "                    WHEN 'JANEIRO' THEN 'JANUARY'\n",
    "                    WHEN 'FEVEREIRO' THEN 'FEBRUARY'\n",
    "                    WHEN 'MARCO' THEN 'MARCH'\n",
    "                    WHEN 'ABRIL' THEN 'APRIL'\n",
    "                    WHEN 'MAIO' THEN 'MAY'\n",
    "                    WHEN 'JUNHO' THEN 'JUNE'\n",
    "                    WHEN 'JULHO' THEN 'JULY'\n",
    "                    WHEN 'AGOSTO' THEN 'AUGUST'\n",
    "                    WHEN 'SETEMBRO' THEN 'SEPTEMBER'\n",
    "                    WHEN 'OUTUBRO' THEN 'OCTOBER'\n",
    "                    WHEN 'NOVEMBRO' THEN 'NOVEMBER'\n",
    "                    WHEN 'DEZEMBRO' THEN 'DECEMBER'\n",
    "                    ELSE monthCompleteTime\n",
    "                END monthCompleteTime,\n",
    "\n",
    "                bimonthTime,\n",
    "                quarterTime,\n",
    "                semesterTime,\n",
    "                yearTime\n",
    "            FROM stagingTime\n",
    "            \"\"\")\n",
    "\n",
    "            # 4. Transformasi fakta Coins\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE OR REPLACE TABLE stagingFactCoins AS\n",
    "            SELECT\n",
    "                keyTime,\n",
    "                keyCoin,\n",
    "                valueCoin\n",
    "            FROM stagingCoinValue\n",
    "            \"\"\")\n",
    "\n",
    "            # 5. Transformasi fakta Stocks\n",
    "            self.conn.execute(\"\"\"\n",
    "            CREATE OR REPLACE TABLE stagingFactStocks AS\n",
    "            SELECT\n",
    "                keyTime,\n",
    "                keyCompany,\n",
    "                openValueStock,\n",
    "                closeValueStock,\n",
    "                highValueStock,\n",
    "                lowValueStock,\n",
    "                quantityStock\n",
    "            FROM stagingStockValue\n",
    "            \"\"\")\n",
    "            \n",
    "            # Hitung jumlah catatan\n",
    "            total_records = 0\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingDimCoin\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingDimCompany\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingDimTime\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingFactCoins\").fetchone()[0]\n",
    "            total_records += self.conn.execute(\"SELECT COUNT(*) FROM stagingFactStocks\").fetchone()[0]\n",
    "\n",
    "            self.log_process_end(log_id, records=total_records, status='SUCCESS')\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
    "            raise\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"Load data ke data warehouse\"\"\"\n",
    "        log_id = self.log_process_start(\"load_data\")\n",
    "        \n",
    "        try:\n",
    "            # Hapus data tabel\n",
    "            self.conn.execute(\"DELETE FROM factCoins\")\n",
    "            self.conn.execute(\"DELETE FROM factStocks\")\n",
    "            self.conn.execute(\"DELETE FROM dimCoin\")\n",
    "            self.conn.execute(\"DELETE FROM dimCompany\")\n",
    "            self.conn.execute(\"DELETE FROM dimTime\")\n",
    "            \n",
    "            # 1. Muat dimensi Coin\n",
    "            self.conn.execute(\"INSERT INTO dimCoin SELECT * FROM stagingDimCoin\")\n",
    "            \n",
    "            # 2. Muat dimensi Company\n",
    "            self.conn.execute(\"INSERT INTO dimCompany SELECT * FROM stagingDimCompany\")\n",
    "            \n",
    "            # 3. Muat dimensi Time\n",
    "            self.conn.execute(\"INSERT INTO dimTime SELECT * FROM stagingDimTime\")\n",
    "            \n",
    "            # 4. Muat fakta Coins dengan pemetaan kunci yang benar\n",
    "            self.conn.execute(\"\"\"\n",
    "            INSERT INTO factCoins\n",
    "            SELECT \n",
    "                t.keyTime,\n",
    "                c.keyCoin,\n",
    "                f.valueCoin\n",
    "            FROM stagingFactCoins f\n",
    "            JOIN dimTime t ON f.keyTime = t.keyTime\n",
    "            JOIN dimCoin c ON f.keyCoin = c.keyCoin\n",
    "            \"\"\")\n",
    "            \n",
    "            # 5. Muat fakta Stocks dengan pemetaan kunci yang benar\n",
    "            self.conn.execute(\"\"\"\n",
    "            INSERT INTO factStocks\n",
    "            SELECT \n",
    "                t.keyTime,\n",
    "                c.keyCompany,\n",
    "                f.openValueStock,\n",
    "                f.closeValueStock,\n",
    "                f.highValueStock,\n",
    "                f.lowValueStock,\n",
    "                f.quantityStock\n",
    "            FROM stagingFactStocks f\n",
    "            JOIN dimTime t ON f.keyTime = t.keyTime\n",
    "            JOIN dimCompany c ON f.keyCompany = c.keyCompany\n",
    "            \"\"\")\n",
    "            \n",
    "            # Menghitung jumlah baris yang dimuat\n",
    "            coin_count = self.conn.execute(\"SELECT COUNT(*) FROM dimCoin\").fetchone()[0]\n",
    "            company_count = self.conn.execute(\"SELECT COUNT(*) FROM dimCompany\").fetchone()[0]\n",
    "            time_count = self.conn.execute(\"SELECT COUNT(*) FROM dimTime\").fetchone()[0]\n",
    "            fact_coin_count = self.conn.execute(\"SELECT COUNT(*) FROM factCoins\").fetchone()[0]\n",
    "            fact_stock_count = self.conn.execute(\"SELECT COUNT(*) FROM factStocks\").fetchone()[0]\n",
    "\n",
    "            total_records = coin_count + company_count + time_count + fact_coin_count + fact_stock_count\n",
    "\n",
    "            self.log_process_end(log_id, records=total_records, status='SUCCESS', \n",
    "                message=f'Loaded {coin_count} coins, {company_count} companies, '\n",
    "                        f'{time_count} time records, {fact_coin_count} coin facts, '\n",
    "                        f'{fact_stock_count} stock facts')\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log_process_end(log_id, status='ERROR', message=str(e))\n",
    "            raise\n",
    "    \n",
    "    def run_full_pipeline(self):\n",
    "        \"\"\"Jalankan seluruh pipeline ETL\"\"\"\n",
    "        print(\"Menjalankan ETL Pipeline lengkap...\")\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # 1. Inisialisasi warehouse\n",
    "            self.initialize_warehouse()\n",
    "            print(\"✓“ Data warehouse diinisialisasi\")\n",
    "            \n",
    "            # 2. Ekstrak data\n",
    "            self.extract_all_sources()\n",
    "            print(\"✓“ Data diekstrak dari semua sumber\")\n",
    "            \n",
    "            # 3. Transform data\n",
    "            self.transform_data()\n",
    "            print(\"✓“ Data ditransformasi\")\n",
    "            \n",
    "            # 4. Load data\n",
    "            self.load_data()\n",
    "            print(\"✓“ Data dimuat ke data warehouse\")\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            duration = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            print(f\"\\nPipeline ETL selesai dalam {duration:.2f} detik\")\n",
    "            \n",
    "            # Menampilkan statistik\n",
    "            stats = self.conn.execute(\"\"\"\n",
    "                SELECT \n",
    "                    (SELECT COUNT(*) FROM dimCoin) as coin_count,\n",
    "                    (SELECT COUNT(*) FROM dimCompany) as company_count,\n",
    "                    (SELECT COUNT(*) FROM dimTime) as time_count,\n",
    "                    (SELECT COUNT(*) FROM factCoins) as fact_coin_count,\n",
    "                    (SELECT COUNT(*) FROM factStocks) as fact_stock_count\n",
    "            \"\"\").fetchone()\n",
    "\n",
    "            print(\"\\nStatistik Data Warehouse:\")\n",
    "            print(f\"✓ Dimensi Coin: {stats[0]} baris\")\n",
    "            print(f\"✓ Dimensi Company: {stats[1]} baris\")\n",
    "            print(f\"✓ Dimensi Time: {stats[2]} baris\")\n",
    "            print(f\"✓ Fakta Coin: {stats[3]} baris\")\n",
    "            print(f\"✓ Fakta Stock: {stats[4]} baris\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Pipeline ETL gagal: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def get_etl_log(self, limit=10):\n",
    "        \"\"\"Menampilkan log ETL terakhir\"\"\"\n",
    "        return self.conn.execute(f\"\"\"\n",
    "            SELECT \n",
    "                logId,\n",
    "                processName,\n",
    "                startTime,\n",
    "                endTime,\n",
    "                EXTRACT(EPOCH FROM (endTime - startTime)) as duration_seconds,\n",
    "                recordsProcessed,\n",
    "                status,\n",
    "                message\n",
    "            FROM etlLog\n",
    "            ORDER BY logId DESC\n",
    "            LIMIT {limit}\n",
    "        \"\"\").fetchdf()\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Menutup koneksi saat objek dihapus\"\"\"\n",
    "        try:\n",
    "            if hasattr(self, 'conn'):\n",
    "                self.conn.close()\n",
    "                print(\"Koneksi DuckDB ditutup.\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "84cc4d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi DuckDB ditutup.\n",
      "Menjalankan ETL Pipeline lengkap...\n",
      "✓“ Data warehouse diinisialisasi\n",
      "✓“ Data diekstrak dari semua sumber\n",
      "✓“ Data ditransformasi\n",
      "✓“ Data dimuat ke data warehouse\n",
      "\n",
      "Pipeline ETL selesai dalam 6.89 detik\n",
      "\n",
      "Statistik Data Warehouse:\n",
      "✓ Dimensi Coin: 2 baris\n",
      "✓ Dimensi Company: 607 baris\n",
      "✓ Dimensi Time: 9680 baris\n",
      "✓ Fakta Coin: 13300 baris\n",
      "✓ Fakta Stock: 680150 baris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = ETLPipeline()\n",
    "pipeline.run_full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ce61663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koneksi DuckDB ditutup.\n"
     ]
    }
   ],
   "source": [
    "# Menutup kelas ETLPipeline\n",
    "del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6a18e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logId</th>\n",
       "      <th>processName</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>recordsProcessed</th>\n",
       "      <th>status</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>transform_data</td>\n",
       "      <td>2025-03-20 22:26:13.063</td>\n",
       "      <td>2025-03-20 22:26:13.416</td>\n",
       "      <td>0.353</td>\n",
       "      <td>703741</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>extract_all_sources</td>\n",
       "      <td>2025-03-20 22:26:12.219</td>\n",
       "      <td>2025-03-20 22:26:13.058</td>\n",
       "      <td>0.839</td>\n",
       "      <td>703741</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>initialize_warehouse</td>\n",
       "      <td>2025-03-20 22:26:12.202</td>\n",
       "      <td>2025-03-20 22:26:12.216</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Data warehouse schema initialized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>transform_data</td>\n",
       "      <td>2025-03-20 22:25:18.547</td>\n",
       "      <td>2025-03-20 22:25:18.888</td>\n",
       "      <td>0.341</td>\n",
       "      <td>703741</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>extract_all_sources</td>\n",
       "      <td>2025-03-20 22:25:17.688</td>\n",
       "      <td>2025-03-20 22:25:18.543</td>\n",
       "      <td>0.855</td>\n",
       "      <td>703741</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>initialize_warehouse</td>\n",
       "      <td>2025-03-20 22:25:17.671</td>\n",
       "      <td>2025-03-20 22:25:17.685</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Data warehouse schema initialized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>transform_data</td>\n",
       "      <td>2025-03-20 22:20:10.415</td>\n",
       "      <td>2025-03-20 22:20:10.420</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Binder Error: Referenced column \"coin_id\" not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>extract_all_sources</td>\n",
       "      <td>2025-03-20 22:20:09.548</td>\n",
       "      <td>2025-03-20 22:20:10.411</td>\n",
       "      <td>0.863</td>\n",
       "      <td>703741</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>initialize_warehouse</td>\n",
       "      <td>2025-03-20 22:20:09.534</td>\n",
       "      <td>2025-03-20 22:20:09.545</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>Data warehouse schema initialized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   logId           processName               startTime  \\\n",
       "0      9        transform_data 2025-03-20 22:26:13.063   \n",
       "1      8   extract_all_sources 2025-03-20 22:26:12.219   \n",
       "2      7  initialize_warehouse 2025-03-20 22:26:12.202   \n",
       "3      6        transform_data 2025-03-20 22:25:18.547   \n",
       "4      5   extract_all_sources 2025-03-20 22:25:17.688   \n",
       "5      4  initialize_warehouse 2025-03-20 22:25:17.671   \n",
       "6      3        transform_data 2025-03-20 22:20:10.415   \n",
       "7      2   extract_all_sources 2025-03-20 22:20:09.548   \n",
       "8      1  initialize_warehouse 2025-03-20 22:20:09.534   \n",
       "\n",
       "                  endTime  duration_seconds  recordsProcessed   status  \\\n",
       "0 2025-03-20 22:26:13.416             0.353            703741  SUCCESS   \n",
       "1 2025-03-20 22:26:13.058             0.839            703741  SUCCESS   \n",
       "2 2025-03-20 22:26:12.216             0.014                 0  SUCCESS   \n",
       "3 2025-03-20 22:25:18.888             0.341            703741  SUCCESS   \n",
       "4 2025-03-20 22:25:18.543             0.855            703741  SUCCESS   \n",
       "5 2025-03-20 22:25:17.685             0.014                 0  SUCCESS   \n",
       "6 2025-03-20 22:20:10.420             0.005                 0    ERROR   \n",
       "7 2025-03-20 22:20:10.411             0.863            703741  SUCCESS   \n",
       "8 2025-03-20 22:20:09.545             0.011                 0  SUCCESS   \n",
       "\n",
       "                                             message  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2                  Data warehouse schema initialized  \n",
       "3                                               None  \n",
       "4                                               None  \n",
       "5                  Data warehouse schema initialized  \n",
       "6  Binder Error: Referenced column \"coin_id\" not ...  \n",
       "7                                               None  \n",
       "8                  Data warehouse schema initialized  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_etl_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa5d23",
   "metadata": {},
   "source": [
    "# Generate Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "520e0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_coin_csv(filepath='data/generated/coin_values.csv', num_rows=100, start_date='2022-01-01'):\n",
    "    # Extract the directory from the filename\n",
    "    dir_path = os.path.dirname(filename)\n",
    "\n",
    "    # Create directory (and all intermediate directories) if not exist\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    start_dt = pd.to_datetime(start_date)\n",
    "    \n",
    "    # Generate random dates using timedelta offsets\n",
    "    random_days = np.random.randint(0, 366, size=num_rows)\n",
    "    time = start_dt + pd.to_timedelta(random_days, unit='D')\n",
    "    \n",
    "    # Random coins\n",
    "    coins = np.random.choice(['USD', 'EUR'], size=num_rows)\n",
    "    \n",
    "    # Random float values\n",
    "    valueCoin = np.round(np.random.uniform(1.0, 5.0, size=num_rows), 4)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'time': time,\n",
    "        'coin': coins,\n",
    "        'valueCoin': valueCoin\n",
    "    })\n",
    "    \n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"✅ CSV generated using NumPy + Pandas: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3d7f82f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data\\generated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_random_coin_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[126], line 21\u001b[0m, in \u001b[0;36mgenerate_random_coin_csv\u001b[1;34m(filepath, num_rows, start_date)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: time,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoin\u001b[39m\u001b[38;5;124m'\u001b[39m: coins,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalueCoin\u001b[39m\u001b[38;5;124m'\u001b[39m: valueCoin\n\u001b[0;32m     19\u001b[0m })\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ CSV generated using NumPy + Pandas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data\\generated'"
     ]
    }
   ],
   "source": [
    "generate_random_coin_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82472106",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e3bd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB (in-memory or file)\n",
    "con = duckdb.connect('brazil_stock_market.db')  # or ':memory:' for in-memory DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7f8b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a343af2",
   "metadata": {},
   "source": [
    "## Debug Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "24d08ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyTime</th>\n",
       "      <th>datetime</th>\n",
       "      <th>dayTime</th>\n",
       "      <th>dayWeekTime</th>\n",
       "      <th>dayWeekAbbrevTime</th>\n",
       "      <th>dayWeekCompleteTime</th>\n",
       "      <th>monthTime</th>\n",
       "      <th>monthAbbrevTime</th>\n",
       "      <th>monthCompleteTime</th>\n",
       "      <th>bimonthTime</th>\n",
       "      <th>quarterTime</th>\n",
       "      <th>semesterTime</th>\n",
       "      <th>yearTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1994-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>SAT</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1994-07-02</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>SUN</td>\n",
       "      <td>SUNDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1994-07-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>MON</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1994-07-04</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>TUE</td>\n",
       "      <td>TUESDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1994-07-05</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>WED</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1994-07-06</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>THU</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1994-07-07</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>FRI</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1994-07-08</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>SAT</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1994-07-09</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>SUN</td>\n",
       "      <td>SUNDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1994-07-10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>MON</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>7</td>\n",
       "      <td>JUL</td>\n",
       "      <td>JULY</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyTime   datetime  dayTime  dayWeekTime dayWeekAbbrevTime  \\\n",
       "0        1 1994-07-01        1            6               SAT   \n",
       "1        2 1994-07-02        2            7               SUN   \n",
       "2        3 1994-07-03        3            1               MON   \n",
       "3        4 1994-07-04        4            2               TUE   \n",
       "4        5 1994-07-05        5            3               WED   \n",
       "5        6 1994-07-06        6            4               THU   \n",
       "6        7 1994-07-07        7            5               FRI   \n",
       "7        8 1994-07-08        8            6               SAT   \n",
       "8        9 1994-07-09        9            7               SUN   \n",
       "9       10 1994-07-10       10            1               MON   \n",
       "\n",
       "  dayWeekCompleteTime  monthTime monthAbbrevTime monthCompleteTime  \\\n",
       "0            SATURDAY          7             JUL              JULY   \n",
       "1              SUNDAY          7             JUL              JULY   \n",
       "2              MONDAY          7             JUL              JULY   \n",
       "3             TUESDAY          7             JUL              JULY   \n",
       "4           WEDNESDAY          7             JUL              JULY   \n",
       "5            THURSDAY          7             JUL              JULY   \n",
       "6              FRIDAY          7             JUL              JULY   \n",
       "7            SATURDAY          7             JUL              JULY   \n",
       "8              SUNDAY          7             JUL              JULY   \n",
       "9              MONDAY          7             JUL              JULY   \n",
       "\n",
       "   bimonthTime  quarterTime  semesterTime  yearTime  \n",
       "0            4            3             2      1994  \n",
       "1            4            3             2      1994  \n",
       "2            4            3             2      1994  \n",
       "3            4            3             2      1994  \n",
       "4            4            3             2      1994  \n",
       "5            4            3             2      1994  \n",
       "6            4            3             2      1994  \n",
       "7            4            3             2      1994  \n",
       "8            4            3             2      1994  \n",
       "9            4            3             2      1994  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT * FROM stagingdimTime LIMIT 10\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9d1d625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyTime: BIGINT\n",
      "datetime: DATE\n",
      "dayTime: BIGINT\n",
      "dayWeekTime: BIGINT\n",
      "dayWeekAbbrevTime: VARCHAR\n",
      "dayWeekCompleteTime: VARCHAR\n",
      "monthTime: BIGINT\n",
      "monthAbbrevTime: VARCHAR\n",
      "monthCompleteTime: VARCHAR\n",
      "bimonthTime: BIGINT\n",
      "quarterTime: BIGINT\n",
      "semesterTime: BIGINT\n",
      "yearTime: BIGINT\n",
      "\n",
      "keyTime: INTEGER\n",
      "datetime: VARCHAR\n",
      "dayTime: SMALLINT\n",
      "dayWeekTime: SMALLINT\n",
      "dayWeekAbbrevTime: VARCHAR\n",
      "dayWeekCompleteTime: VARCHAR\n",
      "monthTime: SMALLINT\n",
      "monthAbbrevTime: VARCHAR\n",
      "monthCompleteTime: VARCHAR\n",
      "bimonthTime: SMALLINT\n",
      "quarterTime: SMALLINT\n",
      "semesterTime: SMALLINT\n",
      "yearTime: INTEGER\n"
     ]
    }
   ],
   "source": [
    "info = con.execute(\"PRAGMA table_info('stagingdimTime')\").fetchall()\n",
    "for col in info:\n",
    "    print(f\"{col[1]}: {col[2]}\")\n",
    "\n",
    "print()\n",
    "\n",
    "info = con.execute(\"PRAGMA table_info('dimTime')\").fetchall()\n",
    "for col in info:\n",
    "    print(f\"{col[1]}: {col[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b416b0",
   "metadata": {},
   "source": [
    "## Debug show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b4e8e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimCoin\n",
      "dimCompany\n",
      "dimTime\n",
      "etlLog\n",
      "factCoins\n",
      "factStocks\n",
      "stagingCoin\n",
      "stagingCoinValue\n",
      "stagingCompany\n",
      "stagingStockValue\n",
      "stagingTime\n"
     ]
    }
   ],
   "source": [
    "# Show all tables\n",
    "tables = con.execute(\"SHOW TABLES\").fetchall()\n",
    "\n",
    "# Print the list of tables\n",
    "for table in tables:\n",
    "    print(table[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb823a",
   "metadata": {},
   "source": [
    "## Debug delete all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c896465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables deleted.\n"
     ]
    }
   ],
   "source": [
    "con.execute(f\"DROP TABLE IF EXISTS factCoins\")\n",
    "con.execute(f\"DROP TABLE IF EXISTS factStocks\")\n",
    "\n",
    "# Get list of all tables in the 'main' schema\n",
    "tables = con.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'main'\n",
    "\"\"\").fetchall()\n",
    "\n",
    "# Drop each table\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    con.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "print(\"All tables deleted.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
